{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2018-05-10 10:49:34.862764\n",
      "By yvan\n",
      "Using Python 3.6.5\n",
      "On Linux-4.13.0-36-generic-x86_64-with-debian-stretch-sid\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from runtimestamp.runtimestamp import runtimestamp\n",
    "\n",
    "runtimestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-related global variables\n",
    "max_seq_len = 30\n",
    "min_word_freq = 20\n",
    "\n",
    "# GPU variables\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_num = 1\n",
    "device = torch.device(f\"cuda:{device_num}\" if use_gpu else \"cpu\")\n",
    "\n",
    "# File-writing variables\n",
    "today = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "train_file = '/mnt/hdd2/leon_data/books/3body/en/all_three_train.csv'\n",
    "valid_file = '/mnt/hdd2/leon_data/books/3body/en/all_three_valid.csv'\n",
    "test_file = '/mnt/hdd2/leon_data/books/3body/en/all_three_test.csv'\n",
    "model_dir = '/mnt/hdd2/leon_data/books/models/{}/'.format(today)\n",
    "file_model = os.path.join(model_dir, '3body_LM__{}.json')\n",
    "file_wv = os.path.join(model_dir, '3body_LM__wv__{}.txt')\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexVectorizer:\n",
    "    \"\"\"\n",
    "    Transforms a Corpus into lists of word indices.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_words=None, min_frequency=None, start_end_tokens=False, maxlen=None):\n",
    "        self.vocabulary = None\n",
    "        self.vocabulary_size = 0\n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.max_words = max_words\n",
    "        self.min_frequency = min_frequency\n",
    "        self.start_end_tokens = start_end_tokens\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def _find_max_document_length(self, corpus):\n",
    "        self.maxlen = max(len(document) for document in corpus)\n",
    "        if self.start_end_tokens:\n",
    "            self.maxlen += 2\n",
    "\n",
    "    def _build_vocabulary(self, corpus):\n",
    "        vocabulary = Counter(word for document in corpus for word in document)\n",
    "        if self.max_words:\n",
    "            vocabulary = {word: freq for word,\n",
    "                          freq in vocabulary.most_common(self.max_words)}\n",
    "        if self.min_frequency:\n",
    "            vocabulary = {word: freq for word, freq in vocabulary.items()\n",
    "                          if freq >= self.min_frequency}\n",
    "        self.vocabulary = vocabulary\n",
    "        self.vocabulary_size = len(vocabulary) + 2  # padding and unk tokens\n",
    "        if self.start_end_tokens:\n",
    "            self.vocabulary_size += 2\n",
    "\n",
    "    def _build_word_index(self):\n",
    "        self.word2idx['<PAD>'] = 0\n",
    "        self.word2idx['<UNK>'] = 1\n",
    "\n",
    "        if self.start_end_tokens:\n",
    "            self.word2idx['<START>'] = 2\n",
    "            self.word2idx['<END>'] = 3\n",
    "\n",
    "        offset = len(self.word2idx)\n",
    "        for idx, word in enumerate(self.vocabulary):\n",
    "            self.word2idx[word] = idx + offset\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        if not self.maxlen:\n",
    "            self._find_max_document_length(corpus)\n",
    "        self._build_vocabulary(corpus)\n",
    "        self._build_word_index()\n",
    "\n",
    "    def pad_document_vector(self, vector):\n",
    "        padding = self.maxlen - len(vector)\n",
    "        vector.extend([self.word2idx['<PAD>']] * padding)\n",
    "        return vector\n",
    "\n",
    "    def add_start_end(self, vector):\n",
    "        vector.append(self.word2idx['<END>'])\n",
    "        return [self.word2idx['<START>']] + vector\n",
    "\n",
    "    def transform_document(self, document, offset=0):\n",
    "        \"\"\"\n",
    "        Vectorize a single document\n",
    "        \"\"\"\n",
    "        vector = [self.word2idx.get(word, self.word2idx['<UNK>']) \n",
    "                  for word in document]\n",
    "        if len(vector) > self.maxlen:\n",
    "            vector = vector[:self.maxlen]\n",
    "        if self.start_end_tokens:\n",
    "            vector = self.add_start_end(vector)\n",
    "        vector = vector[offset:self.maxlen]\n",
    "        \n",
    "        return self.pad_document_vector(vector)\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        \"\"\"\n",
    "        Vectorizes a corpus in the form of a list of lists.\n",
    "        A corpus is a list of documents and a document is a list of words.\n",
    "        \"\"\"\n",
    "        return [self.transform_document(document) for document in corpus]\n",
    "    \n",
    "    \n",
    "class ThreeBodyDataset(Dataset):\n",
    "    def __init__(self, path, vectorizer, tokenizer=None, stopwords=None):\n",
    "        self.corpus = pd.read_csv(path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vectorizer = vectorizer\n",
    "        self.stopwords = stopwords\n",
    "        self._tokenize_corpus()\n",
    "        if self.stopwords: self._remove_stopwords() \n",
    "        self._vectorize_corpus()\n",
    "\n",
    "    def _remove_stopwords(self):\n",
    "        stopfilter = lambda doc: [word for word in doc if word not in self.stopwords]\n",
    "        self.corpus['tokens'] = self.corpus['tokens'].apply(stopfilter)\n",
    "\n",
    "    def _tokenize_corpus(self):\n",
    "        if self.tokenizer:\n",
    "            self.corpus['tokens'] = self.corpus['sentences'].apply(self.tokenizer)\n",
    "        else:\n",
    "            self.corpus['tokens'] = self.corpus['sentences'].apply(lambda x: x.lower().split())\n",
    "\n",
    "    def _vectorize_corpus(self):\n",
    "        if not self.vectorizer.vocabulary:\n",
    "            self.vectorizer.fit(self.corpus['tokens'])\n",
    "        self.corpus['vectors'] = self.corpus['tokens'].apply(self.vectorizer.transform_document)\n",
    "        self.corpus['target'] = self.corpus['tokens'].apply(self.vectorizer.transform_document, offset=1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.corpus['vectors'].iloc[index]\n",
    "        target = self.corpus['target'].iloc[index]\n",
    "        return torch.LongTensor(sentence), torch.LongTensor(target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "def simple_tokenizer(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = IndexVectorizer(max_words=None, min_frequency=min_word_freq, \n",
    "                             start_end_tokens=True, maxlen=max_seq_len)\n",
    "\n",
    "training_set = ThreeBodyDataset(train_file, vectorizer, simple_tokenizer)\n",
    "test_set = ThreeBodyDataset(test_file, vectorizer, simple_tokenizer)\n",
    "validation_set = ThreeBodyDataset(valid_file, vectorizer, simple_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10387, 1732, 1731)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1194\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size: {}\".format(vectorizer.vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentences    Purely in terms of command , humanity might ne...\n",
       "tokens       [purely, in, terms, of, command, ,, humanity, ...\n",
       "vectors      [2, 1, 4, 1, 5, 6, 7, 8, 9, 10, 11, 12, 1, 13,...\n",
       "target       [1, 4, 1, 5, 6, 7, 8, 9, 10, 11, 12, 1, 13, 1,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.corpus.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll divide our dataset into a training set and a test set.\n",
    "We'll also create some functions for loading the data into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    print(msg)\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class History(object):\n",
    "    \"\"\"Records Loss and Validation Loss\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.loss = dict()\n",
    "        self.val_loss = dict()\n",
    "        self.min_loss = 100\n",
    "    \n",
    "    def update_min_loss(self, min_loss):\n",
    "        self.min_loss = min_loss\n",
    "        \n",
    "    def update_loss(self, loss):\n",
    "        epoch = len(self.loss.keys())\n",
    "        self.loss[epoch] = loss\n",
    "    \n",
    "    def update_val_loss(self, val_loss):\n",
    "        epoch = len(self.val_loss.keys())\n",
    "        self.val_loss[epoch] = val_loss\n",
    "        \n",
    "    def plot(self):\n",
    "        loss = sorted(self.loss.items())\n",
    "        x, y = zip(*loss)\n",
    "        \n",
    "        if self.val_loss:\n",
    "            val_loss = sorted(self.val_loss.items())\n",
    "            x1, y1 = zip(*val_loss)\n",
    "            plt.plot(x, y, 'C0', label='Loss')\n",
    "            plt.plot(x1, y1, 'C2', label='Validation Loss')\n",
    "            plt.legend();\n",
    "        else:\n",
    "            plt.plot(x, y, 'C0');\n",
    "    \n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    y_true = y_true.float()\n",
    "    _, y_pred = torch.max(y_pred.squeeze(), dim=-1)\n",
    "    return (y_pred.float() == y_true).float().mean()\n",
    "\n",
    "def softmax_trick(x):\n",
    "    logits_exp = torch.exp(x - torch.max(x))\n",
    "    weights = torch.div(logits_exp, logits_exp.sum())\n",
    "    return weights\n",
    "\n",
    "def save_state_dict(model, filepath):\n",
    "    '''Saves the model weights as a dictionary'''\n",
    "    model_dict = model.state_dict()\n",
    "    torch.save(model_dict, filepath)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Language Model\n",
    "Here we'll define a recurrent language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, embedding_size, \n",
    "                 hidden_size, batch_size, \n",
    "                 dropout=.5, num_layers=1, tie_weights=False, \n",
    "                 bidirectional=False, word2idx={}, log_softmax=False):\n",
    "       \n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.tie_weights = tie_weights\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 1 if not bidirectional else 2\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = {v:k for k,v in word2idx.items()}\n",
    "        \n",
    "        # Model Pieces\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1) if log_softmax else None\n",
    "        \n",
    "        # Model Layers\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_size, \n",
    "                                    padding_idx = word2idx.get('<PAD>', 1))\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embedding_size, hidden_size, \n",
    "                             num_layers = 1, \n",
    "                             bidirectional = bidirectional,\n",
    "                             batch_first = True)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_size * self.num_directions, hidden_size, \n",
    "                             num_layers = 1, \n",
    "                             bidirectional = bidirectional,\n",
    "                             batch_first = True)\n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_size * self.num_directions, vocab_size)\n",
    "\n",
    "        # tie enc/dec weights\n",
    "        if self.tie_weights:\n",
    "            if hidden_size != embedding_size:\n",
    "                raise ValueError('When using the `tied` flag, hidden_size'\n",
    "                                 'must be equal to embedding_dim')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "            \n",
    "        self.init_weights()\n",
    "\n",
    "        \n",
    "    def init_hidden(self, bsz=None):\n",
    "        '''\n",
    "        For the nn.LSTM.\n",
    "        Defaults to the batchsize stored in the class params, but can take in an argument\n",
    "        in the case of sampling.\n",
    "        '''\n",
    "        if bsz == None: \n",
    "            bsz = self.batch_size\n",
    "        h0 = torch.zeros(self.num_layers * self.num_directions, \n",
    "                         bsz, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * self.num_directions, \n",
    "                         bsz, self.hidden_size ).to(device)\n",
    "        return (h0, c0)\n",
    "    \n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        em_layer = [self.encoder]\n",
    "        lin_layers = [self.decoder]\n",
    "        for layer in lin_layers + em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)\n",
    "    \n",
    "    \n",
    "    def sample(self, x_start):\n",
    "        '''\n",
    "        Generates a sequence of text given a starting word ix and hidden state.\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            indices = [x_start]\n",
    "            for i in range(self.seq_len):\n",
    "                # create inputs\n",
    "                x_input = torch.LongTensor(indices).to(device)\n",
    "                x_embs = self.encoder(x_input.view(1, -1))\n",
    "\n",
    "                # send input through the rnn\n",
    "                output, hidden = self.lstm1(x_embs)\n",
    "                output, hidden = self.lstm2(output, hidden)\n",
    "\n",
    "                # format the last word of the rnn so we can softmax it.\n",
    "                one_dim_last_word = output.squeeze()[-1] if i > 0 else output.squeeze()\n",
    "                fwd = one_dim_last_word[ : self.hidden_size ]\n",
    "                bck = one_dim_last_word[ self.hidden_size : ]\n",
    "\n",
    "                # pick a word from the disto\n",
    "                word_weights = softmax_trick(fwd)\n",
    "                word_idx = torch.multinomial(word_weights, num_samples=1).squeeze().item()\n",
    "                indices.append(word_idx)\n",
    "\n",
    "        return indices\n",
    "    \n",
    "    \n",
    "    def forward(self, x, hidden, log_softmax=False):\n",
    "        '''\n",
    "        Iterates through the input, encodes it.\n",
    "        Each embedding is sent through the step function.\n",
    "        Dropout the last hidden layer and decode to a logit\n",
    "        x.size() #(bsz, seq_len)\n",
    "        \n",
    "        logit.size # (bsz, seq_len, vocab_size)\n",
    "        equivalent to (output.size(0), output.size(1), logit.size(1)\n",
    "        '''\n",
    "        x_emb = self.encoder(x)\n",
    "        \n",
    "        output, hidden = self.lstm1(x_emb, hidden)\n",
    "        output, hidden = self.lstm2(self.dropout(output), hidden)\n",
    "        \n",
    "        logit = self.decoder(self.dropout(output))\n",
    "        if self.log_softmax:\n",
    "            logit = self.log_softmax(logit)\n",
    "        logit = logit.view(logit.size(0) * self.seq_len, self.vocab_size)\n",
    "        \n",
    "        return logit, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, dataset, criterion, optim, batch_size, \n",
    "              train=False, shuffle=True):\n",
    "    '''A wrapper for a training, validation or test run.'''\n",
    "    model.train() if train else model.eval()\n",
    "    loss = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    for X, y in loader:\n",
    "        model.zero_grad() \n",
    "        X = X.squeeze().to(device)\n",
    "        y = y.squeeze().view(-1).to(device)\n",
    "\n",
    "        # get a predition    \n",
    "        hidden = model.init_hidden(X.size(0))\n",
    "        y_, hidden = model(X, hidden)\n",
    "        \n",
    "        # calculate loss and accuracy\n",
    "        lossy = criterion(y_.squeeze(), y.squeeze())\n",
    "        accy = categorical_accuracy(y_.squeeze().data, y.squeeze().data)\n",
    "        \n",
    "        loss.update(lossy.data.item())\n",
    "        accuracy.update(accy)\n",
    "        \n",
    "        # backprop\n",
    "        if train:\n",
    "            lossy.backward()\n",
    "            optim.step()\n",
    "    \n",
    "    return loss.avg, accuracy.avg\n",
    "\n",
    "\n",
    "def training_epoch(*args, **kwargs):\n",
    "    '''Training Epoch'''\n",
    "    return run_epoch(train=True, *args, **kwargs)\n",
    "    \n",
    "    \n",
    "def validation_epoch(*args, **kwargs):\n",
    "    '''Validation Epoch'''\n",
    "    return run_epoch(*args, **kwargs)\n",
    " \n",
    "    \n",
    "def sample_lm(model):\n",
    "    '''Samples a language model and returns generated words'''\n",
    "    start_idx = model.word2idx['<START>']\n",
    "    indices = model.sample(start_idx)\n",
    "    words = [model.idx2word[index] for index in indices]\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "def training_loop(batch_size, num_epochs, display_freq, model, criterion, \n",
    "                  optim, training_set, validation_set=None, \n",
    "                  best_model_path='model', history=None):\n",
    "    '''Training iteration.'''\n",
    "    if not history:\n",
    "        history = History()\n",
    "    \n",
    "    try: \n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            loss, accuracy = training_epoch(model, training_set, criterion, optim, batch_size)\n",
    "            history.update_loss(loss)\n",
    "            \n",
    "            if validation_set:\n",
    "                val_loss, val_accuracy = validation_epoch(model, validation_set, \n",
    "                                                          criterion, optim, batch_size)  \n",
    "                history.update_val_loss(val_loss)\n",
    "                if val_loss < history.min_loss:\n",
    "                    save_state_dict(model, best_model_path)\n",
    "                    history.update_min_loss(val_loss)\n",
    "            else:\n",
    "                if loss < history.min_loss:\n",
    "                    save_state_dict(model, best_model_path)\n",
    "                    history.update_min_loss(loss)\n",
    "                \n",
    "            if epoch % display_freq == 0:\n",
    "                # display stats\n",
    "                if validation_set:\n",
    "                    log(\"Epoch: {:04d}; Loss: {:.4f}; Val-Loss {:.4f}; \"\n",
    "                        \"Perplexity {:.4f}; Val-Perplexity {:.4f}\".format(\n",
    "                            epoch, loss, val_loss, np.exp(loss), np.exp(val_loss)))\n",
    "                else:\n",
    "                    log(\"Epoch: {:04d}; Loss: {:.4f}; Perplexity {:.4f};\".format(\n",
    "                            epoch, loss, np.exp(loss)))\n",
    "                \n",
    "                # sample from the language model\n",
    "                words = sample_lm(model)\n",
    "                log(\"Sample: {}\".format(' '.join(words)))\n",
    "                time.sleep(1)\n",
    "        \n",
    "        log('-' * 89)\n",
    "        log(\"Training complete\")\n",
    "        log(\"Lowest loss: {:.4f}\".format(history.min_loss))\n",
    "        \n",
    "        return  history\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        log('-' * 89)\n",
    "        log('Exiting from training early')\n",
    "        log(\"Lowest loss: {:.4f}\".format(history.min_loss))\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "We'll declare hyperparameters here, instantiate our model, create a training set data batcher, and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1a935e70ea479da77be58502e33b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000; Loss: 3.3905; Val-Loss 3.3774; Perplexity 29.6801; Val-Perplexity 29.2938\n",
      "Sample: <START> day about away they quickly morning lit away these image use use day in three quickly - . command <START> by see but transmission this her this <PAD> something transmission\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yvan/anaconda3/envs/leon_pytorch/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yvan/anaconda3/envs/leon_pytorch/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/yvan/anaconda3/envs/leon_pytorch/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010; Loss: 2.7412; Val-Loss 2.7036; Perplexity 15.5052; Val-Perplexity 14.9334\n",
      "Sample: <START> soon cigarette star his ji luo an about history had <PAD> got might but command in this children walking was children an when and quickly but with centuries star glanced\n",
      "Epoch: 0020; Loss: 2.6513; Val-Loss 2.6180; Perplexity 14.1722; Val-Perplexity 13.7078\n",
      "Sample: <START> space , . her see transmission time walking several <PAD> his it edge speed seemed not walking was might out display it , something lit and can morning up soon\n",
      "Epoch: 0030; Loss: 2.3643; Val-Loss 2.3149; Perplexity 10.6371; Val-Perplexity 10.1237\n",
      "Sample: <START> <END> was ! they when turned five universe this these <START> a quickly seemed display lit of but several never wang he held its want about by use something red\n",
      "Epoch: 0040; Loss: 2.0659; Val-Loss 2.0162; Perplexity 7.8925; Val-Perplexity 7.5095\n",
      "Sample: <START> as wang humanity already see time look in walking can by five up <END> red with turned space away you transmission with lit his these got a three in want\n",
      "Epoch: 0050; Loss: 1.8465; Val-Loss 1.7997; Perplexity 6.3377; Val-Perplexity 6.0475\n",
      "Sample: <START> might star morning it as about noticed morning on had history started might command by see with three speed command never never out in image , was at was turned\n",
      "Epoch: 0060; Loss: 1.6731; Val-Loss 1.6281; Perplexity 5.3288; Val-Perplexity 5.0940\n",
      "Sample: <START> that never her direction soon was ! already but only past universe in something in universe glanced space space space his in about seemed five in in you a two\n",
      "Epoch: 0070; Loss: 1.5413; Val-Loss 1.5004; Perplexity 4.6705; Val-Perplexity 4.4834\n",
      "Sample: <START> see to it direction it you never lit might red hands these luo not started transmission : however its up children saw saw held this the lit transmission ! like\n",
      "Epoch: 0080; Loss: 1.4411; Val-Loss 1.4104; Perplexity 4.2254; Val-Perplexity 4.0975\n",
      "Sample: <START> out want the ji two but two five ! by got wang morning out might out have look battle . day use away were battle lit were her on had\n",
      "Epoch: 0090; Loss: 1.3598; Val-Loss 1.3254; Perplexity 3.8956; Val-Perplexity 3.7637\n",
      "Sample: <START> not hands only transmission was - look however the was lit got like her transmission were half hands of they have , as the look they look however seemed centuries\n",
      "Epoch: 0100; Loss: 1.2966; Val-Loss 1.2670; Perplexity 3.6568; Val-Perplexity 3.5501\n",
      "Sample: <START> something hands in hands image hands might past saw it you started star lit glanced about transmission by was lit had got lit as at not image red something trisolaris\n",
      "Epoch: 0110; Loss: 1.2488; Val-Loss 1.2281; Perplexity 3.4861; Val-Perplexity 3.4148\n",
      "Sample: <START> , you light five - by noticed lit and <PAD> want three but walking got have transmission these turned with wang out her cigarette seemed two <START> an half transmission\n",
      "Epoch: 0120; Loss: 1.2097; Val-Loss 1.1952; Perplexity 3.3524; Val-Perplexity 3.3042\n",
      "Sample: <START> centuries her battle were out speed soon half held cigarette on seemed might glanced morning when transmission two as noticed never five see in turned be that use to you\n",
      "Epoch: 0130; Loss: 1.1852; Val-Loss 1.1774; Perplexity 3.2712; Val-Perplexity 3.2460\n",
      "Sample: <START> as can with her these seemed its history noticed <START> direction to past something out display trisolaris light red were was - day got might noticed in something use universe\n",
      "Epoch: 0140; Loss: 1.1666; Val-Loss 1.1600; Perplexity 3.2112; Val-Perplexity 3.1898\n",
      "Sample: <START> to got its star seemed cigarette look had something . have had star with not two that <END> trisolaris and light her luo : light direction like an be transmission\n",
      "Epoch: 0150; Loss: 1.1460; Val-Loss 1.1398; Perplexity 3.1456; Val-Perplexity 3.1260\n",
      "Sample: <START> look about lit it glanced wang time these like direction <START> they about at seemed his image day out with he of not when ji its cigarette humanity day not\n",
      "Epoch: 0160; Loss: 1.1350; Val-Loss 1.1276; Perplexity 3.1112; Val-Perplexity 3.0882\n",
      "Sample: <START> something <END> display started time want display away it held humanity saw luo command at she not saw started morning be several children hands cigarette these past day luo however\n",
      "Epoch: 0170; Loss: 1.1251; Val-Loss 1.1225; Perplexity 3.0805; Val-Perplexity 3.0726\n",
      "Sample: <START> was time to in on not lit her - look want his wang only got past however like several however star he seemed had held the and glanced when star\n",
      "Epoch: 0180; Loss: 1.1154; Val-Loss 1.1086; Perplexity 3.0507; Val-Perplexity 3.0301\n",
      "Sample: <START> on about not have on several <END> might image glanced hands that turned might universe with held had ! want saw these noticed cigarette cigarette <UNK> they children not these\n",
      "Epoch: 0190; Loss: 1.1087; Val-Loss 1.1054; Perplexity 3.0303; Val-Perplexity 3.0203\n",
      "Sample: <START> her not humanity to however speed want a in cigarette in these you these seemed had out its with speed lit - was several were only its ! image soon\n",
      "Epoch: 0200; Loss: 1.1046; Val-Loss 1.1010; Perplexity 3.0180; Val-Perplexity 3.0073\n",
      "Sample: <START> her but however direction red : soon five it have morning glanced the <START> a seemed direction this want noticed on away might his <START> its glanced be three speed\n",
      "Epoch: 0210; Loss: 1.0969; Val-Loss 1.0958; Perplexity 2.9948; Val-Perplexity 2.9915\n",
      "Sample: <START> direction transmission past saw started however held the see of of a seemed day only as morning space about you transmission look like a have was cigarette you star lit\n",
      "Epoch: 0220; Loss: 1.0922; Val-Loss 1.0979; Perplexity 2.9809; Val-Perplexity 2.9980\n",
      "Sample: <START> luo never can luo - turned to have morning something the when cigarette want wang see you an the direction an transmission on its its got already you its edge\n",
      "Epoch: 0230; Loss: 1.0894; Val-Loss 1.0973; Perplexity 2.9725; Val-Perplexity 2.9961\n",
      "Sample: <START> three light you this see speed started transmission might he something glanced use with light might an history star as past speed noticed you battle something an by her .\n",
      "Epoch: 0240; Loss: 1.0848; Val-Loss 1.0963; Perplexity 2.9588; Val-Perplexity 2.9930\n",
      "Sample: <START> wang see morning seemed centuries by these <PAD> a humanity like seemed morning and were be past started morning ! <PAD> of three cigarette these ! about only held when\n",
      "Epoch: 0250; Loss: 1.0828; Val-Loss 1.0886; Perplexity 2.9529; Val-Perplexity 2.9702\n",
      "Sample: <START> never never however . its an never with held on want got when with had an started two her command speed three held noticed its <UNK> see saw speed about\n",
      "Epoch: 0260; Loss: 1.0798; Val-Loss 1.0921; Perplexity 2.9441; Val-Perplexity 2.9805\n",
      "Sample: <START> wang at up morning red its these cigarette only <END> held not command five noticed seemed at got his seemed in as battle - something edge and quickly day by\n",
      "Epoch: 0270; Loss: 1.0771; Val-Loss 1.0810; Perplexity 2.9362; Val-Perplexity 2.9475\n",
      "Sample: <START> <UNK> only a transmission like cigarette her glanced history have cigarette you had had see walking you her glanced two soon its trisolaris but the three red noticed want not\n",
      "Epoch: 0280; Loss: 1.0761; Val-Loss 1.0786; Perplexity 2.9333; Val-Perplexity 2.9406\n",
      "Sample: <START> her her in seemed to transmission had - got image saw see was was might but as speed centuries soon had like had never her never had <PAD> they day\n",
      "Epoch: 0290; Loss: 1.0753; Val-Loss 1.0849; Perplexity 2.9308; Val-Perplexity 2.9591\n",
      "Sample: <START> had not you centuries red cigarette history with red hands its red when was trisolaris had held saw the by have command battle had hands speed soon were time five\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Training complete\n",
      "Lowest loss: 1.0744\n"
     ]
    }
   ],
   "source": [
    "# Set Seed\n",
    "if use_gpu: torch.cuda.manual_seed(303)\n",
    "else: torch.manual_seed(303)\n",
    "\n",
    "# set up Files to save stuff in\n",
    "runtime = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "file_model = file_model.format(runtime)\n",
    "file_wv = file_wv.format(runtime)\n",
    "    \n",
    "# Model Hyper Parameters \n",
    "hidden_dim = 100\n",
    "embedding_dim = 200\n",
    "batch_size = 512\n",
    "dropout = 0.2\n",
    "lstm_layers = 1 # this is useless atm\n",
    "lstm_bidirection = True\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 300\n",
    "display_epoch_freq = 10\n",
    "\n",
    "# Build and initialize the model\n",
    "lm = RNNLM(vectorizer.vocabulary_size, max_seq_len, embedding_dim, hidden_dim, batch_size, \n",
    "           dropout = dropout, \n",
    "           tie_weights = False, \n",
    "           num_layers = lstm_layers, \n",
    "           bidirectional = lstm_bidirection, \n",
    "           word2idx = vectorizer.word2idx,\n",
    "           log_softmax = True)\n",
    "\n",
    "if use_gpu:\n",
    "    lm = lm.to(device)\n",
    "lm.init_weights()\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(lm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "history = training_loop(batch_size, num_epochs, display_epoch_freq, \n",
    "                        lm, loss, optimizer, training_set, validation_set, \n",
    "                        best_model_path=file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(batch_size, model, criterion, optim, test_set,):\n",
    "    '''Data iterator for the test set'''\n",
    "    model.eval()\n",
    "    \n",
    "    try:\n",
    "        test_loss, test_accuracy = validation_epoch(model, test_set, \n",
    "                                                    criterion, optim, batch_size)\n",
    "        log('Evaluation Complete')\n",
    "        log('Test set Loss: {}'.format(test_loss))\n",
    "        log('Test set Perplexity: {}'.format(np.exp(test_loss)))\n",
    "        log('Test set Accuracy: {}'.format(test_accuracy))\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        log('-' * 89)\n",
    "        log('Exiting from testing early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete\n",
      "Test set Loss: 1.0961862802505493\n",
      "Test set Perplexity: 2.992730795887753\n",
      "Test set Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "lm.load_state_dict(torch.load(file_model))\n",
    "test_loop(256, lm, loss, optimizer, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Embeddings Weights\n",
    "1. Extrcting vectors into a dictionary (`word2vec`)\n",
    "2. Saving the vectors (`word2vec`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_vectors(model):\n",
    "    model.eval()\n",
    "    word2vec = {}\n",
    "    for w, ix in tqdm(model.word2idx.items()):\n",
    "        ix_var = torch.LongTensor([ix]).to(device)\n",
    "\n",
    "        emb = model.encoder(ix_var.view(1,-1))\n",
    "        out1, hid_ = model.lstm1(emb)\n",
    "        out2, hid_ = model.lstm2(out1, hid_)\n",
    "        \n",
    "        emb = emb.view(1,-1).data.cpu().numpy()[0]\n",
    "        out1 = out1.view(1,-1).data.cpu().numpy()[0]\n",
    "        out2 = out2.view(1,-1).data.cpu().numpy()[0]\n",
    "\n",
    "        word2vec[w] = dict(\n",
    "            embedding = emb,\n",
    "            hid1 = out1,\n",
    "            hid2 = out2,\n",
    "        )\n",
    "        \n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e844542301407795eeff7e1f81c7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = get_elmo_vectors(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03af59176b1a4caa98c263f36aac44e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file_wv, 'w+') as f:\n",
    "    for w, vec in tqdm(word2vec.items()):\n",
    "        row = np.concatenate([[w], vec['embedding'], vec['hid1'], vec['hid2']])\n",
    "        f.write(' '.join(row) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doomsday 0.019144375 -0.011262503 -0.054264653 0.07552316 -0.04677312 -0.043715246 0.029800449 -0.098677255 -0.087699786 0.111737646 0.08108406 0.08127617 0.14914002 -0.17581704 0.010354878 0.12268086 -0.08209066 -0.03954192 -0.009683989 0.060234316 0.079789676 -0.11663191 0.124724835 -0.037095707 0.04702442 -0.029397946 -0.12079265 -0.10139638 0.0095835645 0.113344245 0.08293821 0.100370824 -0.008190885 0.008966734 0.021829829 -0.08489138 0.10120566 -0.010230141 -0.04472376 -0.10047493 -0.0625175 -0.055764224 0.1547271 -0.1139233 -0.057975918 -0.11362845 -0.047995884 -0.028644199 0.031366825 0.09102691 0.0064217034 0.0591397 -0.034809817 -0.030157201 -0.055808205 0.017484395 0.057290915 0.056935456 0.04440339 0.03640528 0.061410222 -0.06576907 -0.066208206 0.009575155 0.09143286 -0.10088797 -0.08211959 0.059557542 -0.035395663 0.024542004 -0.035210326 0.014628755 0.12772882 -0.057329144 -0.0744061 -0.02468062 0.009410101 -0.04309125 -0.084312454 0.0762925 -0.020742945 0.04448962 0.12309611 0.016032873 0.15162481 -0.1314242 0.12193378 0.08225759 0.029561715 -0.0614505 0.006002207 -0.0927667 -0.065466516 -0.06480242 0.0077024833 0.020869521 -0.0758709 0.090688854 0.03706296 0.0017705106 0.043391243 -0.14248165 0.05658515 0.07355731 0.07907174 0.019258726 -0.08251391 -0.061569046 -0.07022654 0.038820278 -0.0878327 -0.041754447 0.014912813 -0.015131595 0.0001365648 -0.00984699 -0.11710193 0.027462937 -0.07352145 0.033495378 0.020122392 0.095105104 0.0015523405 -0.05174806 -0.055938885 0.08180001 -0.115246415 0.039961703 -0.047477294 0.021761438 -0.01935918 0.037725147 -0.045951545 0.059311435 0.003186048 -0.09801708 0.100893565 0.050895005 0.09025452 0.054864142 0.109954745 0.16359329 -0.036519982 0.10660204 -0.070585296 -0.03825811 0.008745374 -0.006380331 0.066654995 0.0025552027 -0.053807035 0.038850956 -0.031916663 0.08099706 -0.010193364 -0.12841539 -0.019125786 -0.034416553 0.056395948 -0.0029892267 0.034501243 0.058722064 -0.043787777 -0.14189883 -0.06835651 -0.011339926 0.071666695 -0.053338896 0.074751765 0.07303199 -0.080664754 -0.0674444 0.021041414 -0.11712903 0.015653785 -0.10301745 0.13191797 0.03336045 0.073667005 0.02220278 0.018015405 -0.04430134 -0.050868444 0.13137431 -0.12607768 -0.04385574 0.10287586 -0.02199097 -0.046265874 -0.046365585 0.03192538 -0.05965421 -0.008514234 0.06323657 0.11607088 0.043476973 0.006071745 -0.03002573 0.079065256 0.10162905 0.123988666 -0.11351591 0.012707224 0.033863965 -0.038223825 0.04719314 -0.04606858 -0.011751718 0.04507148 -0.0048624175 0.042390265 -0.13216378 -0.076352164 0.0075225094 0.061840795 0.2257554 -0.06922411 -0.089413665 -0.022556232 -0.07062854 -0.11332289 -0.007943083 0.10174688 0.016032528 0.076806374 0.016981956 0.071279734 0.00037128598 -0.0088539515 -0.0195572 -0.1138637 -0.037353866 -0.043936227 0.16313241 -0.05448641 0.14080141 0.015675344 -0.09355434 0.033032957 0.13163991 -0.04940434 0.027297204 0.011381093 0.07453263 -0.027582524 0.047562845 -0.17956817 -0.15048222 -0.075844266 0.164489 0.0888622 -0.054217402 -0.11419919 -0.046849623 0.0032962284 0.12490391 0.02095681 0.07558962 -0.0038533907 -0.07554676 0.07734367 -0.08135916 -0.013699127 0.048568472 -0.0627778 0.10186819 -0.08268394 -0.09364053 -0.11943724 -0.047317725 0.02201621 0.045001548 0.09462936 0.048074357 -0.05612918 0.0825079 -0.088830166 -0.03815688 -0.09791671 0.00797545 0.026351817 -0.091244705 -0.011592205 -0.05384624 0.0487457 -0.11188113 -0.05003087 -0.009712308 0.02694161 -0.009335604 0.024024239 -0.1270577 -0.14116967 -0.027769063 0.06540114 0.07800534 -0.08499379 0.076454766 0.09255872 -0.12363913 -0.101437315 0.007894608 0.17152315 0.00042451595 0.024041355 -0.041437272 0.050027844 -0.02760984 0.021333607 -0.049038976 0.03679542 -0.14440495 -0.029170137 -0.0027979224 -0.004392188 0.015992261 -0.021676196 -0.1323027 -0.0015445176 0.21564086 -0.013431105 -0.0061001927 -0.032708876 -0.04209167 0.054932624 -0.01859128 -0.11102446 -0.09928766 0.043740373 0.09106052 0.064958274 -0.06324171 0.1484803 0.21339355 -0.15271601 0.055790193 -0.07014506 0.020499673 0.0046761455 -0.009467079 0.06724552 0.17583278 -0.20661941 0.021186551 0.13845748 -0.019551588 0.1073641 -0.032113653 0.12176157 0.04607929 0.07857493 0.04625448 -0.0724659 -0.13722306 -0.10848629 -0.015127993 -0.052834637 -0.080647975 -0.18753123 0.13316339 -0.18373246 0.044140592 0.030956859 0.082465254 -0.09925594 0.029463645 0.048026074 0.06725748 -0.022498338 0.30080742 -0.04067377 0.18708871 -0.05891599 -0.034532316 -0.02673782 -0.0774335 -0.03408435 -0.07535319 -0.16249557 0.15918423 -0.045513082 -0.026489092 0.063562505 0.0035445625 0.04143385 0.054864183 0.11467244 -0.006415189 -0.017656647 0.02820999 -0.12635364 -0.017223196 -0.020308511 0.09518707 -0.20856085 -0.10820239 -0.118585385 0.051283766 -0.01944336 0.010883282 -0.15552144 -0.026531573 -0.0022704673 -0.07406549 0.15039048 -0.09156772 0.19901429 -0.11889205 -0.027131049 0.13789564 0.21246442 0.085902646 0.030998515 -0.18561736 0.13175236 0.10126359 0.06693361 -0.14071806 0.09460603 -0.20043278 0.08795798 0.1279674 -0.14521612 -0.08201606 -0.07542526 0.045425393 0.25055277 -0.2020613 -0.09616534 -0.12523662 0.059590247 -0.08095756 0.13505952 0.014808842 -0.039542053 0.37339324 -0.042027168 -0.032162536 0.11853116 0.1960998 -0.17258637 -0.044939574 0.05499272 -0.0019374555 0.0815436 -0.06386393 0.15047418 -0.2258666 -0.062035587 -0.03271413 0.046317052 0.15558659 -0.15382297 -0.13178296 -0.14106806 0.054497693 -0.10640273 0.2416711 -0.08302012 -0.14271438 -0.0866469 0.1034047 -0.018578123 -0.14366029 0.08044761 -0.015542477 0.209219 -0.2218885 -0.04830695 0.1617367 0.100623764 0.12184961 -0.062163666 0.19608174 -0.07673878 -0.04012129 -0.22895329 -0.13467328 0.012120137 0.040390603 0.10485775 0.15833047 0.19763793 0.0932549 0.07177312 -0.05330936 -0.025881646 0.01982425 -0.050485928 0.17094877 0.061567124 -0.19522922 -0.11896508 0.067274734 -0.04687178 0.025645025 -0.1969956 -0.07138407 0.00557158 -0.27678615 -0.22383045 -0.27760637 0.13022874 0.10331432 -0.08814418 0.23716603 0.023350634 -0.28934518 0.15164366 -0.08098609 0.13166778 -0.1763806 -0.16157448 0.028121786 0.14172442 0.06670422 0.07928535 0.008279952 -0.0639333 0.17381434 -0.08439902 0.2515398 -0.04096333 -0.073651336 0.21865274 0.18785118 0.22600447 0.16057311 0.11348682 -0.10273971 0.04218584 0.008524662 -0.10813271 0.066350296 -0.09815816 0.12081578 -0.030189963 0.17794281 -0.17870511 0.25373653 -0.037956443 -0.0125516895 0.03886509 -0.08524119 0.28474876 0.09443538 0.28689948 0.25865027 0.16293843 -0.1992543 -0.04438634 -0.15152445 0.10258499 -0.08918362 0.13862842 0.19983067 0.1311691 0.0499539 0.12701514 -0.09394877 -0.19378224 -0.060368024 -0.31211683 -0.18064882 0.09889215 -0.1825807 0.21072602 -0.008927809 -0.093034856 -0.10520393 0.14345038 0.016104385 0.13663946 -0.09954506 -0.086325355 0.087362535 -0.33888233 -0.20934108 0.14313582 0.17845821 -0.25092235 0.10741558 -0.036945153 0.13091739 -0.29757756 -0.091621876 -0.06711745 -0.16859876 0.22402763 -0.21097897 0.13412702 0.12645882 0.13199389 0.07841743 -0.03782335 -0.24159867 -0.23621875 0.10574535 0.15957592 0.15734378'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
